{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRBSI Prediction - MIMIC-IV Data Preprocessing\n",
    "## Multi-Task Learning with Static and Temporal Features\n",
    "\n",
    "This notebook preprocesses MIMIC-IV data for CRBSI prediction using SMTAFormer architecture.\n",
    "\n",
    "**Features:**\n",
    "- Static: Demographics, catheter characteristics, baseline labs, comorbidities\n",
    "- Temporal: Vital signs (hourly), Labs (daily), Catheter events (daily)\n",
    "- Outcome: CRBSI occurrence (binary classification + time-to-event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set!\n",
      "Feature window: 48h\n",
      "Prediction window: 72h\n",
      "Survival tracking: 168h\n"
     ]
    }
   ],
   "source": [
    "# Path to MIMIC-IV data (update these paths to your data location)\n",
    "MIMIC_PATH = 'MIMIC-IV (3.1)/'  # UPDATE THIS\n",
    "HOSP_PATH = MIMIC_PATH + 'hosp/'\n",
    "ICU_PATH = MIMIC_PATH + 'icu/'\n",
    "\n",
    "# Output path\n",
    "OUTPUT_PATH = MIMIC_PATH\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Time windows configuration\n",
    "FEATURE_WINDOW_HOURS = 48  # Look back 48 hours for feature extraction\n",
    "PREDICTION_WINDOW_HOURS = 72  # Predict CRBSI in next 72 hours\n",
    "SURVIVAL_WINDOW_HOURS = 168  # Track up to 7 days for survival analysis\n",
    "\n",
    "# Temporal sequence lengths (for model input)\n",
    "VITAL_SEQ_LENGTH = 48  # 48 hours of hourly vitals\n",
    "LAB_SEQ_LENGTH = 14  # 7 days × 2 measurements/day\n",
    "CATHETER_EVENT_SEQ_LENGTH = 14  # 14 days of daily catheter events\n",
    "\n",
    "print(f\"Configuration set!\")\n",
    "print(f\"Feature window: {FEATURE_WINDOW_HOURS}h\")\n",
    "print(f\"Prediction window: {PREDICTION_WINDOW_HOURS}h\")\n",
    "print(f\"Survival tracking: {SURVIVAL_WINDOW_HOURS}h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Core MIMIC-IV Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading core tables...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading core tables...\")\n",
    "\n",
    "# Core patient information\n",
    "patients = pd.read_csv(HOSP_PATH + 'patients.csv')\n",
    "admissions = pd.read_csv(HOSP_PATH + 'admissions.csv')\n",
    "icustays = pd.read_csv(ICU_PATH + 'icustays.csv')\n",
    "transfers = pd.read_csv(HOSP_PATH + 'transfers.csv')\n",
    "\n",
    "# Diagnoses and procedures\n",
    "diagnoses_icd = pd.read_csv(HOSP_PATH + 'diagnoses_icd.csv')\n",
    "d_icd_diagnoses = pd.read_csv(HOSP_PATH + 'd_icd_diagnoses.csv')\n",
    "procedures_icd = pd.read_csv(HOSP_PATH + 'procedures_icd.csv')\n",
    "\n",
    "# Labs and microbiology\n",
    "labevents = pd.read_csv(HOSP_PATH + 'labevents.csv.gz', \n",
    "                        usecols=['subject_id', 'hadm_id', 'itemid', 'charttime', 'value', 'valuenum'] , low_memory=False)\n",
    "d_labitems = pd.read_csv(HOSP_PATH + 'd_labitems.csv')\n",
    "microbiologyevents = pd.read_csv(HOSP_PATH + 'microbiologyevents.csv')\n",
    "\n",
    "# ICU data\n",
    "chartevents = pd.read_csv(ICU_PATH + 'chartevents.csv.gz',\n",
    "                         usecols=['subject_id', 'hadm_id', 'stay_id', 'itemid', 'charttime', 'value', 'valuenum'] , low_memory=False)\n",
    "d_items = pd.read_csv(ICU_PATH + 'd_items.csv')\n",
    "procedureevents = pd.read_csv(ICU_PATH + 'procedureevents.csv')\n",
    "\n",
    "# Pharmacy\n",
    "prescriptions = pd.read_csv(HOSP_PATH + 'prescriptions.csv')\n",
    "\n",
    "print(f\"Loaded data for {len(patients)} patients\")\n",
    "print(f\"Loaded {len(admissions)} admissions\")\n",
    "print(f\"Loaded {len(icustays)} ICU stays\")\n",
    "print(f\"Chart events: {len(chartevents):,} records\")\n",
    "print(f\"Lab events: {len(labevents):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Central Line and CRBSI Identification\n",
    "\n",
    "Based on the clinical presentation slides, we identify:\n",
    "- Central line types: CVC, PICC, Hickman, Port-A, Swan-Ganz, Midline\n",
    "- CRBSI criteria: Positive blood culture + catheter culture with same organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central line procedure codes (ICD-9 and ICD-10)\n",
    "CENTRAL_LINE_CODES = {\n",
    "    # ICD-9\n",
    "    '3893': 'Venous catheterization',\n",
    "    '3895': 'Venous catheterization for renal dialysis',\n",
    "    '8607': 'Insertion of totally implantable vascular access device',\n",
    "    # ICD-10\n",
    "    '02H60JZ': 'Insertion of central venous catheter',\n",
    "    '02HV3JZ': 'Insertion of tunneled central venous catheter',\n",
    "    '02HV33Z': 'Insertion of PICC',\n",
    "    '05H033Z': 'Insertion of infusion device into superior vena cava'\n",
    "}\n",
    "\n",
    "# CRBSI-related diagnosis codes\n",
    "CRBSI_CODES = {\n",
    "    # ICD-9\n",
    "    '99931': 'Infection due to central venous catheter',\n",
    "    '99632': 'Bloodstream infection due to central venous catheter',\n",
    "    # ICD-10  \n",
    "    'T80211A': 'Bloodstream infection due to central venous catheter',\n",
    "    'T80212A': 'Local infection due to central venous catheter',\n",
    "    'T80218A': 'Other infection due to central venous catheter',\n",
    "    'T80219A': 'Unspecified infection due to central venous catheter'\n",
    "}\n",
    "\n",
    "# Common CRBSI pathogens (from slide 10)\n",
    "CRBSI_ORGANISMS = [\n",
    "    'STAPHYLOCOCCUS AUREUS',\n",
    "    'STAPHYLOCOCCUS, COAGULASE NEGATIVE',\n",
    "    'ENTEROCOCCUS',\n",
    "    'ESCHERICHIA COLI',\n",
    "    'KLEBSIELLA PNEUMONIAE',\n",
    "    'PSEUDOMONAS AERUGINOSA',\n",
    "    'ACINETOBACTER BAUMANNII',\n",
    "    'CANDIDA'\n",
    "]\n",
    "\n",
    "print(\"Central line and CRBSI criteria defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify Central Line Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify patients with central line procedures\n",
    "central_line_procedures = procedures_icd[\n",
    "    procedures_icd['icd_code'].isin(CENTRAL_LINE_CODES.keys())\n",
    "].copy()\n",
    "\n",
    "# Parse datetime\n",
    "central_line_procedures['chartdate'] = pd.to_datetime(central_line_procedures['chartdate'])\n",
    "\n",
    "# Merge with admissions and ICU stays\n",
    "central_line_stays = icustays.merge(\n",
    "    central_line_procedures[['subject_id', 'hadm_id', 'chartdate']],\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Parse ICU times\n",
    "central_line_stays['intime'] = pd.to_datetime(central_line_stays['intime'])\n",
    "central_line_stays['outtime'] = pd.to_datetime(central_line_stays['outtime'])\n",
    "\n",
    "# Filter: central line placed during or before ICU stay\n",
    "central_line_stays = central_line_stays[\n",
    "    central_line_stays['chartdate'] <= central_line_stays['outtime']\n",
    "]\n",
    "\n",
    "# Calculate catheter duration (approximate)\n",
    "central_line_stays['catheter_duration_hours'] = (\n",
    "    central_line_stays['outtime'] - central_line_stays['chartdate']\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "# Filter: Keep stays with catheter duration > 48 hours (clinical relevance)\n",
    "central_line_stays = central_line_stays[\n",
    "    central_line_stays['catheter_duration_hours'] >= 48\n",
    "]\n",
    "\n",
    "print(f\"Identified {len(central_line_stays)} ICU stays with central lines\")\n",
    "print(f\"Unique patients: {central_line_stays['subject_id'].nunique()}\")\n",
    "print(f\"\\nCatheter duration statistics (hours):\")\n",
    "print(central_line_stays['catheter_duration_hours'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Identify CRBSI Cases\n",
    "\n",
    "CRBSI definition (from slides):\n",
    "1. Same organism from blood sample AND catheter tip\n",
    "2. Bacterial load from catheter : peripheral blood ≥ 10:1\n",
    "3. DTP (Differential Time to Positive) ≥ 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify CRBSI from diagnosis codes\n",
    "crbsi_diagnoses = diagnoses_icd[\n",
    "    diagnoses_icd['icd_code'].isin(CRBSI_CODES.keys())\n",
    "][['subject_id', 'hadm_id', 'icd_code']].copy()\n",
    "\n",
    "# Identify CRBSI from microbiology (blood culture positive for CRBSI organisms)\n",
    "microbiologyevents['charttime'] = pd.to_datetime(microbiologyevents['charttime'])\n",
    "\n",
    "blood_cultures = microbiologyevents[\n",
    "    (microbiologyevents['spec_type_desc'].str.contains('BLOOD', case=False, na=False)) &\n",
    "    (microbiologyevents['org_name'].str.upper().isin([org.upper() for org in CRBSI_ORGANISMS]))\n",
    "].copy()\n",
    "\n",
    "# Combine CRBSI identifications\n",
    "crbsi_hadm_ids = set(crbsi_diagnoses['hadm_id'].unique()) | set(blood_cultures['hadm_id'].unique())\n",
    "\n",
    "# Tag CRBSI in central line stays\n",
    "central_line_stays['crbsi'] = central_line_stays['hadm_id'].isin(crbsi_hadm_ids).astype(int)\n",
    "\n",
    "# For CRBSI cases, try to find the timing from microbiology\n",
    "crbsi_timing = blood_cultures.groupby('hadm_id')['charttime'].min().reset_index()\n",
    "crbsi_timing.columns = ['hadm_id', 'crbsi_time']\n",
    "\n",
    "central_line_stays = central_line_stays.merge(crbsi_timing, on='hadm_id', how='left')\n",
    "\n",
    "# Calculate time to CRBSI (for survival analysis)\n",
    "central_line_stays['time_to_crbsi_hours'] = (\n",
    "    central_line_stays['crbsi_time'] - central_line_stays['chartdate']\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "# For non-CRBSI cases, time to event is catheter removal time (censored)\n",
    "central_line_stays.loc[central_line_stays['crbsi'] == 0, 'time_to_crbsi_hours'] = \\\n",
    "    central_line_stays.loc[central_line_stays['crbsi'] == 0, 'catheter_duration_hours']\n",
    "\n",
    "print(f\"\\nCRBSI Cases: {central_line_stays['crbsi'].sum()}\")\n",
    "print(f\"Non-CRBSI Cases: {(central_line_stays['crbsi'] == 0).sum()}\")\n",
    "print(f\"CRBSI Rate: {central_line_stays['crbsi'].mean():.2%}\")\n",
    "print(f\"\\nTime to CRBSI (hours) for CRBSI cases:\")\n",
    "print(central_line_stays[central_line_stays['crbsi'] == 1]['time_to_crbsi_hours'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Static Features\n",
    "\n",
    "Static features (from Enhanced Architecture Specification):\n",
    "- Demographics: age, sex, BMI, race\n",
    "- Catheter: type, site, duration at baseline, number of lumens, insertion location\n",
    "- Clinical context: neutropenia, immunosuppression, ICU, mechanical ventilation, TPN, diabetes, CKD\n",
    "- Baseline labs: WBC, CRP, albumin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_static_features(stay_row, patients_df, admissions_df, diagnoses_df, labevents_df):\n",
    "    \"\"\"\n",
    "    Extract static features for a given ICU stay\n",
    "    \"\"\"\n",
    "    subject_id = stay_row['subject_id']\n",
    "    hadm_id = stay_row['hadm_id']\n",
    "    catheter_time = stay_row['chartdate']\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # ===== DEMOGRAPHICS =====\n",
    "    patient = patients_df[patients_df['subject_id'] == subject_id].iloc[0]\n",
    "    admission = admissions_df[admissions_df['hadm_id'] == hadm_id].iloc[0]\n",
    "    \n",
    "    # Age at admission\n",
    "    features['age'] = patient['anchor_age']\n",
    "    \n",
    "    # Sex (M=1, F=0)\n",
    "    features['sex'] = 1 if patient['gender'] == 'M' else 0\n",
    "    \n",
    "    # Race (simplified categories)\n",
    "    race_map = {\n",
    "        'WHITE': 0, 'BLACK': 1, 'HISPANIC': 2, 'ASIAN': 3, 'OTHER': 4\n",
    "    }\n",
    "    race = admission['race'].upper()\n",
    "    for key in race_map:\n",
    "        if key in race:\n",
    "            features['race'] = race_map[key]\n",
    "            break\n",
    "    else:\n",
    "        features['race'] = 4  # OTHER\n",
    "    \n",
    "    # BMI (would need to calculate from weight/height in chartevents - simplified here)\n",
    "    features['bmi'] = np.nan  # Placeholder - requires height/weight extraction\n",
    "    \n",
    "    # ===== CATHETER CHARACTERISTICS =====\n",
    "    # These would ideally come from procedure notes or itemids\n",
    "    # For now, we'll use placeholders\n",
    "    features['catheter_type'] = 0  # 0=CVC, 1=PICC, 2=Hickman, 3=Port, etc.\n",
    "    features['insertion_site'] = 0  # 0=Subclavian, 1=Jugular, 2=Femoral\n",
    "    features['catheter_duration_baseline'] = 0  # Days at prediction time\n",
    "    features['number_of_lumens'] = 2  # 1, 2, or 3+\n",
    "    features['insertion_location'] = 1  # 0=OR, 1=ICU, 2=bedside, 3=IR\n",
    "    \n",
    "    # ===== COMORBIDITIES (from diagnoses) =====\n",
    "    patient_diagnoses = diagnoses_df[diagnoses_df['hadm_id'] == hadm_id]['icd_code'].values\n",
    "    \n",
    "    # Neutropenia (ICD codes)\n",
    "    neutropenia_codes = ['28800', '28801', '28802', '28803', '28809', 'D70']\n",
    "    features['neutropenia'] = int(any(code in str(patient_diagnoses) for code in neutropenia_codes))\n",
    "    \n",
    "    # Immunosuppression\n",
    "    immunosupp_codes = ['279', 'D84', 'D89']\n",
    "    features['immunosuppression'] = int(any(code in str(patient_diagnoses) for code in immunosupp_codes))\n",
    "    \n",
    "    # Diabetes\n",
    "    diabetes_codes = ['250', 'E10', 'E11']\n",
    "    features['diabetes'] = int(any(code in str(patient_diagnoses) for code in diabetes_codes))\n",
    "    \n",
    "    # CKD stage (simplified)\n",
    "    ckd_codes = ['585', 'N18']\n",
    "    features['ckd_stage'] = int(any(code in str(patient_diagnoses) for code in ckd_codes))\n",
    "    \n",
    "    # ICU admission\n",
    "    features['icu_admission'] = 1  # All are in ICU by definition\n",
    "    \n",
    "    # Mechanical ventilation (would need procedureevents - placeholder)\n",
    "    features['mechanical_ventilation'] = 0\n",
    "    \n",
    "    # TPN use (would need prescriptions - placeholder)\n",
    "    features['tpn_use'] = 0\n",
    "    \n",
    "    # ===== BASELINE LABS =====\n",
    "    # Get labs within 24h before catheter insertion\n",
    "    baseline_labs = labevents_df[\n",
    "        (labevents_df['subject_id'] == subject_id) &\n",
    "        (labevents_df['charttime'] >= catheter_time - pd.Timedelta(hours=24)) &\n",
    "        (labevents_df['charttime'] <= catheter_time)\n",
    "    ]\n",
    "    \n",
    "    # WBC (itemid 51300, 51301)\n",
    "    wbc = baseline_labs[baseline_labs['itemid'].isin([51300, 51301])]['valuenum'].median()\n",
    "    features['baseline_wbc'] = wbc if not pd.isna(wbc) else 10.0  # Default normal\n",
    "    \n",
    "    # CRP (itemid 50889)\n",
    "    crp = baseline_labs[baseline_labs['itemid'] == 50889]['valuenum'].median()\n",
    "    features['baseline_crp'] = crp if not pd.isna(crp) else 5.0\n",
    "    \n",
    "    # Albumin (itemid 50862)\n",
    "    albumin = baseline_labs[baseline_labs['itemid'] == 50862]['valuenum'].median()\n",
    "    features['baseline_albumin'] = albumin if not pd.isna(albumin) else 3.5\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"Static feature extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract static features for all stays (sample first 100 for testing)\n",
    "print(\"Extracting static features...\")\n",
    "\n",
    "# Parse datetime columns in labevents if not already done\n",
    "labevents['charttime'] = pd.to_datetime(labevents['charttime'])\n",
    "\n",
    "static_features_list = []\n",
    "\n",
    "for idx, row in tqdm(central_line_stays.head(100).iterrows(), total=100):\n",
    "    features = extract_static_features(\n",
    "        row, patients, admissions, diagnoses_icd, labevents\n",
    "    )\n",
    "    features['stay_id'] = row['stay_id']\n",
    "    features['subject_id'] = row['subject_id']\n",
    "    features['hadm_id'] = row['hadm_id']\n",
    "    static_features_list.append(features)\n",
    "\n",
    "static_features_df = pd.DataFrame(static_features_list)\n",
    "\n",
    "print(f\"\\nExtracted static features for {len(static_features_df)} stays\")\n",
    "print(f\"\\nStatic features shape: {static_features_df.shape}\")\n",
    "print(\"\\nStatic features preview:\")\n",
    "display(static_features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Temporal Features - Channel 1: Vital Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vital signs itemids (from MIMIC-IV d_items)\n",
    "VITAL_ITEMIDS = {\n",
    "    'heart_rate': [220045],  # Heart Rate\n",
    "    'temperature': [223761, 223762],  # Temperature Fahrenheit, Celsius\n",
    "    'sbp': [220050, 220179],  # Systolic BP (invasive and non-invasive)\n",
    "    'dbp': [220051, 220180],  # Diastolic BP\n",
    "    'map': [220052, 220181, 225312],  # Mean Arterial Pressure\n",
    "    'respiratory_rate': [220210, 224690],  # Respiratory Rate\n",
    "    'spo2': [220277],  # SpO2\n",
    "    'gcs_total': [226755]  # Glasgow Coma Scale Total\n",
    "}\n",
    "\n",
    "def extract_vital_signs(stay_row, chartevents_df, window_hours=48):\n",
    "    \"\"\"\n",
    "    Extract hourly vital signs for specified window\n",
    "    Returns: DataFrame with hourly resampled vital signs\n",
    "    \"\"\"\n",
    "    stay_id = stay_row['stay_id']\n",
    "    catheter_time = stay_row['chartdate']\n",
    "    \n",
    "    # Define time window\n",
    "    start_time = catheter_time\n",
    "    end_time = catheter_time + pd.Timedelta(hours=window_hours)\n",
    "    \n",
    "    # Get all vital signs for this stay in the window\n",
    "    vitals = chartevents_df[\n",
    "        (chartevents_df['stay_id'] == stay_id) &\n",
    "        (chartevents_df['charttime'] >= start_time) &\n",
    "        (chartevents_df['charttime'] <= end_time) &\n",
    "        (chartevents_df['itemid'].isin([item for items in VITAL_ITEMIDS.values() for item in items]))\n",
    "    ].copy()\n",
    "    \n",
    "    if len(vitals) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Map itemids to feature names\n",
    "    itemid_to_feature = {}\n",
    "    for feature, itemids in VITAL_ITEMIDS.items():\n",
    "        for itemid in itemids:\n",
    "            itemid_to_feature[itemid] = feature\n",
    "    \n",
    "    vitals['feature'] = vitals['itemid'].map(itemid_to_feature)\n",
    "    \n",
    "    # Pivot to wide format\n",
    "    vitals_pivot = vitals.pivot_table(\n",
    "        index='charttime',\n",
    "        columns='feature',\n",
    "        values='valuenum',\n",
    "        aggfunc='median'\n",
    "    )\n",
    "    \n",
    "    # Resample to hourly and forward-fill\n",
    "    vitals_hourly = vitals_pivot.resample('1H').median()\n",
    "    vitals_hourly = vitals_hourly.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Ensure we have exactly window_hours rows\n",
    "    expected_index = pd.date_range(start=start_time, periods=window_hours, freq='1H')\n",
    "    vitals_hourly = vitals_hourly.reindex(expected_index)\n",
    "    vitals_hourly = vitals_hourly.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Add time index\n",
    "    vitals_hourly['hour'] = range(len(vitals_hourly))\n",
    "    \n",
    "    return vitals_hourly\n",
    "\n",
    "print(\"Vital signs extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extract Temporal Features - Channel 2: Laboratory Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab itemids\n",
    "LAB_ITEMIDS = {\n",
    "    'wbc_count': [51300, 51301],  # White Blood Cells\n",
    "    'neutrophil_count': [51256],  # Absolute Neutrophil Count\n",
    "    'crp': [50889],  # C-Reactive Protein\n",
    "    'procalcitonin': [51449],  # Procalcitonin\n",
    "    'lactate': [50813],  # Lactate\n",
    "    'platelets': [51265],  # Platelet Count\n",
    "    'creatinine': [50912]  # Creatinine\n",
    "}\n",
    "\n",
    "def extract_lab_values(stay_row, labevents_df, window_days=7):\n",
    "    \"\"\"\n",
    "    Extract lab values over window period\n",
    "    Returns: DataFrame with daily resampled labs\n",
    "    \"\"\"\n",
    "    subject_id = stay_row['subject_id']\n",
    "    hadm_id = stay_row['hadm_id']\n",
    "    catheter_time = stay_row['chartdate']\n",
    "    \n",
    "    # Define time window\n",
    "    start_time = catheter_time\n",
    "    end_time = catheter_time + pd.Timedelta(days=window_days)\n",
    "    \n",
    "    # Get all labs for this admission in the window\n",
    "    labs = labevents_df[\n",
    "        (labevents_df['subject_id'] == subject_id) &\n",
    "        (labevents_df['hadm_id'] == hadm_id) &\n",
    "        (labevents_df['charttime'] >= start_time) &\n",
    "        (labevents_df['charttime'] <= end_time) &\n",
    "        (labevents_df['itemid'].isin([item for items in LAB_ITEMIDS.values() for item in items]))\n",
    "    ].copy()\n",
    "    \n",
    "    if len(labs) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Map itemids to feature names\n",
    "    itemid_to_feature = {}\n",
    "    for feature, itemids in LAB_ITEMIDS.items():\n",
    "        for itemid in itemids:\n",
    "            itemid_to_feature[itemid] = feature\n",
    "    \n",
    "    labs['feature'] = labs['itemid'].map(itemid_to_feature)\n",
    "    \n",
    "    # Pivot to wide format\n",
    "    labs_pivot = labs.pivot_table(\n",
    "        index='charttime',\n",
    "        columns='feature',\n",
    "        values='valuenum',\n",
    "        aggfunc='median'\n",
    "    )\n",
    "    \n",
    "    # Resample to 12-hour intervals (2 per day)\n",
    "    labs_12h = labs_pivot.resample('12H').median()\n",
    "    labs_12h = labs_12h.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Ensure we have expected number of measurements\n",
    "    expected_index = pd.date_range(start=start_time, periods=window_days*2, freq='12H')\n",
    "    labs_12h = labs_12h.reindex(expected_index)\n",
    "    labs_12h = labs_12h.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Add time index\n",
    "    labs_12h['measurement'] = range(len(labs_12h))\n",
    "    \n",
    "    return labs_12h\n",
    "\n",
    "print(\"Lab values extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extract Temporal Features - Channel 3: Catheter Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catheter care event itemids (these are examples - may need adjustment)\n",
    "CATHETER_EVENT_ITEMIDS = {\n",
    "    'dressing_change': [225111, 225112],  # Dressing changes\n",
    "    'line_access': [225158],  # Line access\n",
    "    'blood_draw': [225168, 227719],  # Blood draw from line\n",
    "    'medication_admin': [225168],  # Medication administration\n",
    "    'line_flush': [225166],  # Line flush\n",
    "    'site_assessment': [224263]  # Site assessment/inflammation\n",
    "}\n",
    "\n",
    "def extract_catheter_events(stay_row, procedureevents_df, chartevents_df, window_days=14):\n",
    "    \"\"\"\n",
    "    Extract catheter care events over window period\n",
    "    Returns: DataFrame with daily event counts\n",
    "    \"\"\"\n",
    "    stay_id = stay_row['stay_id']\n",
    "    catheter_time = stay_row['chartdate']\n",
    "    \n",
    "    # Define time window\n",
    "    start_time = catheter_time\n",
    "    end_time = catheter_time + pd.Timedelta(days=window_days)\n",
    "    \n",
    "    # Get events from both procedureevents and chartevents\n",
    "    procedure_events = procedureevents_df[\n",
    "        (procedureevents_df['stay_id'] == stay_id) &\n",
    "        (procedureevents_df['starttime'] >= start_time) &\n",
    "        (procedureevents_df['starttime'] <= end_time)\n",
    "    ].copy()\n",
    "    \n",
    "    chart_events = chartevents_df[\n",
    "        (chartevents_df['stay_id'] == stay_id) &\n",
    "        (chartevents_df['charttime'] >= start_time) &\n",
    "        (chartevents_df['charttime'] <= end_time) &\n",
    "        (chartevents_df['itemid'].isin([item for items in CATHETER_EVENT_ITEMIDS.values() for item in items]))\n",
    "    ].copy()\n",
    "    \n",
    "    # Create daily bins\n",
    "    date_range = pd.date_range(start=start_time.date(), periods=window_days, freq='D')\n",
    "    \n",
    "    catheter_events = pd.DataFrame(index=date_range)\n",
    "    catheter_events['day'] = range(len(catheter_events))\n",
    "    \n",
    "    # Count daily events (simplified - would need more detailed mapping)\n",
    "    if len(chart_events) > 0:\n",
    "        chart_events['date'] = chart_events['charttime'].dt.date\n",
    "        daily_counts = chart_events.groupby('date').size()\n",
    "        catheter_events['line_access_count'] = catheter_events.index.map(daily_counts).fillna(0)\n",
    "    else:\n",
    "        catheter_events['line_access_count'] = 0\n",
    "    \n",
    "    if len(procedure_events) > 0:\n",
    "        procedure_events['date'] = procedure_events['starttime'].dt.date\n",
    "        daily_counts = procedure_events.groupby('date').size()\n",
    "        catheter_events['medication_admin_count'] = catheter_events.index.map(daily_counts).fillna(0)\n",
    "    else:\n",
    "        catheter_events['medication_admin_count'] = 0\n",
    "    \n",
    "    # Add placeholder features (would need more detailed extraction)\n",
    "    catheter_events['blood_draw_count'] = 0\n",
    "    catheter_events['dressing_change'] = 0\n",
    "    catheter_events['site_assessment_score'] = 0\n",
    "    catheter_events['line_flush_count'] = 0\n",
    "    \n",
    "    return catheter_events\n",
    "\n",
    "print(\"Catheter events extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Complete Patient Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse datetime in chartevents if not already done\n",
    "chartevents['charttime'] = pd.to_datetime(chartevents['charttime'])\n",
    "\n",
    "# Extract temporal features for a sample of patients\n",
    "print(\"Extracting temporal features for sample patients...\")\n",
    "\n",
    "complete_dataset = []\n",
    "\n",
    "for idx, row in tqdm(central_line_stays.head(10).iterrows(), total=10):\n",
    "    patient_data = {\n",
    "        'stay_id': row['stay_id'],\n",
    "        'subject_id': row['subject_id'],\n",
    "        'hadm_id': row['hadm_id'],\n",
    "        'crbsi': row['crbsi'],\n",
    "        'time_to_event': row['time_to_crbsi_hours'],\n",
    "        'event': row['crbsi']  # 1 if CRBSI occurred, 0 if censored\n",
    "    }\n",
    "    \n",
    "    # Extract static features\n",
    "    static_feats = extract_static_features(row, patients, admissions, diagnoses_icd, labevents)\n",
    "    patient_data['static_features'] = static_feats\n",
    "    \n",
    "    # Extract temporal features\n",
    "    try:\n",
    "        vitals = extract_vital_signs(row, chartevents, window_hours=FEATURE_WINDOW_HOURS)\n",
    "        labs = extract_lab_values(row, labevents, window_days=7)\n",
    "        catheter = extract_catheter_events(row, procedureevents, chartevents, window_days=14)\n",
    "        \n",
    "        if vitals is not None:\n",
    "            patient_data['vital_signs'] = vitals\n",
    "        if labs is not None:\n",
    "            patient_data['lab_values'] = labs\n",
    "        if catheter is not None:\n",
    "            patient_data['catheter_events'] = catheter\n",
    "            \n",
    "        complete_dataset.append(patient_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing stay_id {row['stay_id']}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nSuccessfully processed {len(complete_dataset)} patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Prepare Data for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_inputs(patient_data, vital_seq_len=48, lab_seq_len=14, catheter_seq_len=14):\n",
    "    \"\"\"\n",
    "    Prepare data in the format required by SMTAFormer\n",
    "    \n",
    "    Returns:\n",
    "        - static_vector: (m,) array of static features\n",
    "        - temporal_sequences: list of 3 arrays for [vitals, labs, catheter_events]\n",
    "        - labels: dict with 'binary', 'time', 'event', 'decision'\n",
    "    \"\"\"\n",
    "    # Static features\n",
    "    static_dict = patient_data['static_features']\n",
    "    static_keys = ['age', 'sex', 'race', 'bmi', 'catheter_type', 'insertion_site',\n",
    "                   'catheter_duration_baseline', 'number_of_lumens', 'insertion_location',\n",
    "                   'neutropenia', 'immunosuppression', 'icu_admission', 'mechanical_ventilation',\n",
    "                   'tpn_use', 'diabetes', 'ckd_stage', 'baseline_wbc', 'baseline_crp', 'baseline_albumin']\n",
    "    \n",
    "    static_vector = np.array([static_dict.get(k, 0) for k in static_keys], dtype=np.float32)\n",
    "    \n",
    "    # Temporal sequences\n",
    "    temporal_sequences = []\n",
    "    \n",
    "    # Vital signs: (seq_len, n_features)\n",
    "    if 'vital_signs' in patient_data:\n",
    "        vitals = patient_data['vital_signs']\n",
    "        vital_cols = ['heart_rate', 'temperature', 'sbp', 'dbp', 'map', 'respiratory_rate', 'spo2', 'gcs_total']\n",
    "        vital_array = vitals[vital_cols].values[:vital_seq_len].astype(np.float32)\n",
    "        \n",
    "        # Pad if necessary\n",
    "        if len(vital_array) < vital_seq_len:\n",
    "            padding = np.zeros((vital_seq_len - len(vital_array), len(vital_cols)), dtype=np.float32)\n",
    "            vital_array = np.vstack([vital_array, padding])\n",
    "        \n",
    "        temporal_sequences.append(vital_array)\n",
    "    else:\n",
    "        temporal_sequences.append(np.zeros((vital_seq_len, 8), dtype=np.float32))\n",
    "    \n",
    "    # Lab values: (seq_len, n_features)\n",
    "    if 'lab_values' in patient_data:\n",
    "        labs = patient_data['lab_values']\n",
    "        lab_cols = ['wbc_count', 'neutrophil_count', 'crp', 'procalcitonin', 'lactate', 'platelets', 'creatinine']\n",
    "        lab_array = labs[lab_cols].values[:lab_seq_len].astype(np.float32)\n",
    "        \n",
    "        if len(lab_array) < lab_seq_len:\n",
    "            padding = np.zeros((lab_seq_len - len(lab_array), len(lab_cols)), dtype=np.float32)\n",
    "            lab_array = np.vstack([lab_array, padding])\n",
    "        \n",
    "        temporal_sequences.append(lab_array)\n",
    "    else:\n",
    "        temporal_sequences.append(np.zeros((lab_seq_len, 7), dtype=np.float32))\n",
    "    \n",
    "    # Catheter events: (seq_len, n_features)\n",
    "    if 'catheter_events' in patient_data:\n",
    "        catheter = patient_data['catheter_events']\n",
    "        catheter_cols = ['line_access_count', 'blood_draw_count', 'medication_admin_count',\n",
    "                        'dressing_change', 'site_assessment_score', 'line_flush_count']\n",
    "        catheter_array = catheter[catheter_cols].values[:catheter_seq_len].astype(np.float32)\n",
    "        \n",
    "        if len(catheter_array) < catheter_seq_len:\n",
    "            padding = np.zeros((catheter_seq_len - len(catheter_array), len(catheter_cols)), dtype=np.float32)\n",
    "            catheter_array = np.vstack([catheter_array, padding])\n",
    "        \n",
    "        temporal_sequences.append(catheter_array)\n",
    "    else:\n",
    "        temporal_sequences.append(np.zeros((catheter_seq_len, 6), dtype=np.float32))\n",
    "    \n",
    "    # Labels\n",
    "    labels = {\n",
    "        'binary': patient_data['crbsi'],  # Binary CRBSI occurrence\n",
    "        'time': patient_data['time_to_event'],  # Time to event (hours)\n",
    "        'event': patient_data['event'],  # Event indicator (1=event, 0=censored)\n",
    "        'decision': 2  # Decision label (0=remove_now, 1=remove_24h, 2=continue) - needs clinical rule\n",
    "    }\n",
    "    \n",
    "    # Generate decision label based on risk and clinical necessity\n",
    "    if labels['binary'] == 1 and labels['time'] < 24:\n",
    "        labels['decision'] = 0  # REMOVE_IMMEDIATELY\n",
    "    elif labels['binary'] == 1 and labels['time'] < 72:\n",
    "        labels['decision'] = 1  # REMOVE_WITHIN_24H\n",
    "    else:\n",
    "        labels['decision'] = 2  # CONTINUE_WITH_MONITORING\n",
    "    \n",
    "    return static_vector, temporal_sequences, labels\n",
    "\n",
    "print(\"Model input preparation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare all patient data for model\n",
    "print(\"Preparing model inputs...\")\n",
    "\n",
    "model_data = []\n",
    "\n",
    "for patient_data in complete_dataset:\n",
    "    try:\n",
    "        static, temporal, labels = prepare_model_inputs(patient_data)\n",
    "        \n",
    "        model_data.append({\n",
    "            'stay_id': patient_data['stay_id'],\n",
    "            'subject_id': patient_data['subject_id'],\n",
    "            'static': static,\n",
    "            'temporal': temporal,\n",
    "            'labels': labels\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing data for stay {patient_data['stay_id']}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nPrepared {len(model_data)} samples for model training\")\n",
    "\n",
    "# Show example\n",
    "if len(model_data) > 0:\n",
    "    example = model_data[0]\n",
    "    print(f\"\\nExample data structure:\")\n",
    "    print(f\"Static features shape: {example['static'].shape}\")\n",
    "    print(f\"Vital signs shape: {example['temporal'][0].shape}\")\n",
    "    print(f\"Lab values shape: {example['temporal'][1].shape}\")\n",
    "    print(f\"Catheter events shape: {example['temporal'][2].shape}\")\n",
    "    print(f\"Labels: {example['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Data Normalization and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def normalize_and_impute(model_data):\n",
    "    \"\"\"\n",
    "    Normalize static and temporal features\n",
    "    Impute missing values\n",
    "    \"\"\"\n",
    "    # Extract all static features for normalization\n",
    "    all_static = np.array([d['static'] for d in model_data])\n",
    "    \n",
    "    # Impute missing values (mean strategy)\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    all_static_imputed = imputer.fit_transform(all_static)\n",
    "    \n",
    "    # Normalize (z-score)\n",
    "    scaler_static = StandardScaler()\n",
    "    all_static_normalized = scaler_static.fit_transform(all_static_imputed)\n",
    "    \n",
    "    # Update static features in model_data\n",
    "    for i, data in enumerate(model_data):\n",
    "        data['static'] = all_static_normalized[i]\n",
    "    \n",
    "    # Normalize temporal features\n",
    "    for channel_idx in range(3):  # 3 temporal channels\n",
    "        # Collect all data for this channel\n",
    "        all_temporal = np.vstack([d['temporal'][channel_idx] for d in model_data])\n",
    "        \n",
    "        # Reshape for normalization\n",
    "        n_samples = len(model_data)\n",
    "        seq_len, n_features = model_data[0]['temporal'][channel_idx].shape\n",
    "        \n",
    "        # Impute and normalize\n",
    "        all_temporal_reshaped = all_temporal.reshape(-1, n_features)\n",
    "        all_temporal_imputed = imputer.fit_transform(all_temporal_reshaped)\n",
    "        \n",
    "        scaler_temporal = StandardScaler()\n",
    "        all_temporal_normalized = scaler_temporal.fit_transform(all_temporal_imputed)\n",
    "        \n",
    "        # Reshape back\n",
    "        all_temporal_normalized = all_temporal_normalized.reshape(n_samples, seq_len, n_features)\n",
    "        \n",
    "        # Update in model_data\n",
    "        for i, data in enumerate(model_data):\n",
    "            data['temporal'][channel_idx] = all_temporal_normalized[i]\n",
    "    \n",
    "    return model_data, scaler_static\n",
    "\n",
    "# Apply normalization\n",
    "print(\"Normalizing and imputing data...\")\n",
    "model_data_normalized, static_scaler = normalize_and_impute(model_data)\n",
    "\n",
    "print(\"\\nNormalization complete!\")\n",
    "print(f\"Static features - Mean: {model_data_normalized[0]['static'].mean():.3f}, Std: {model_data_normalized[0]['static'].std():.3f}\")\n",
    "print(f\"Temporal features (vitals) - Mean: {model_data_normalized[0]['temporal'][0].mean():.3f}, Std: {model_data_normalized[0]['temporal'][0].std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save processed data\n",
    "print(\"Saving processed data...\")\n",
    "\n",
    "# Save as pickle\n",
    "with open(OUTPUT_PATH + 'crbsi_processed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data_normalized, f)\n",
    "\n",
    "# Save scaler for future use\n",
    "with open(OUTPUT_PATH + 'static_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(static_scaler, f)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'n_samples': len(model_data_normalized),\n",
    "    'n_crbsi_cases': sum(d['labels']['binary'] for d in model_data_normalized),\n",
    "    'feature_window_hours': FEATURE_WINDOW_HOURS,\n",
    "    'prediction_window_hours': PREDICTION_WINDOW_HOURS,\n",
    "    'static_features': static_keys,\n",
    "    'vital_signs_features': ['heart_rate', 'temperature', 'sbp', 'dbp', 'map', 'respiratory_rate', 'spo2', 'gcs_total'],\n",
    "    'lab_features': ['wbc_count', 'neutrophil_count', 'crp', 'procalcitonin', 'lactate', 'platelets', 'creatinine'],\n",
    "    'catheter_event_features': ['line_access_count', 'blood_draw_count', 'medication_admin_count', 'dressing_change', 'site_assessment_score', 'line_flush_count']\n",
    "}\n",
    "\n",
    "with open(OUTPUT_PATH + 'metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(f\"\\nData saved to {OUTPUT_PATH}\")\n",
    "print(f\"Total samples: {metadata['n_samples']}\")\n",
    "print(f\"CRBSI cases: {metadata['n_crbsi_cases']}\")\n",
    "print(f\"CRBSI rate: {metadata['n_crbsi_cases']/metadata['n_samples']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Data Summary and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Binary outcome distribution\n",
    "ax = axes[0, 0]\n",
    "binary_labels = [d['labels']['binary'] for d in model_data_normalized]\n",
    "ax.bar(['No CRBSI', 'CRBSI'], [binary_labels.count(0), binary_labels.count(1)])\n",
    "ax.set_title('Binary Outcome Distribution')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "# Time to event distribution\n",
    "ax = axes[0, 1]\n",
    "times = [d['labels']['time'] for d in model_data_normalized if d['labels']['event'] == 1]\n",
    "ax.hist(times, bins=20, edgecolor='black')\n",
    "ax.set_title('Time to CRBSI (for events)')\n",
    "ax.set_xlabel('Hours')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "# Decision distribution\n",
    "ax = axes[1, 0]\n",
    "decisions = [d['labels']['decision'] for d in model_data_normalized]\n",
    "decision_names = ['Remove Now', 'Remove 24h', 'Continue']\n",
    "ax.bar(decision_names, [decisions.count(0), decisions.count(1), decisions.count(2)])\n",
    "ax.set_title('Decision Label Distribution')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "# Example vital signs trajectory\n",
    "ax = axes[1, 1]\n",
    "if len(model_data_normalized) > 0:\n",
    "    example_vitals = model_data_normalized[0]['temporal'][0]  # First patient's vitals\n",
    "    ax.plot(example_vitals[:, 0], label='Heart Rate')\n",
    "    ax.plot(example_vitals[:, 1], label='Temperature')\n",
    "    ax.plot(example_vitals[:, 6], label='SpO2')\n",
    "    ax.set_title('Example Vital Signs Trajectory (Normalized)')\n",
    "    ax.set_xlabel('Hour')\n",
    "    ax.set_ylabel('Normalized Value')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH + 'data_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData summary visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Next Steps\n",
    "\n",
    "The preprocessed data is now ready for model training. Next steps:\n",
    "\n",
    "1. **Split data** into train/validation/test sets\n",
    "2. **Implement SMTAFormer** architecture (3 prediction heads)\n",
    "3. **Define loss functions** for multi-task learning:\n",
    "   - Binary: Focal Loss\n",
    "   - Survival: Cox Partial Likelihood\n",
    "   - Decision: Custom decision loss\n",
    "4. **Train model** with early stopping\n",
    "5. **Evaluate** on test set:\n",
    "   - Binary: AUC, Precision, Recall\n",
    "   - Survival: C-index\n",
    "   - Decision: Accuracy, Confusion Matrix\n",
    "6. **Clinical validation** and interpretation\n",
    "\n",
    "See the Enhanced_CRBSI_Architecture_Specification.md for detailed model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nProcessed {len(model_data_normalized)} patient samples\")\n",
    "print(f\"CRBSI cases: {sum(d['labels']['binary'] for d in model_data_normalized)}\")\n",
    "print(f\"\\nData saved to: {OUTPUT_PATH}\")\n",
    "print(f\"\\nReady for model training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
